{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Map Business Terms to Data Headers"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nIn this notebook we programmatically publish a dataset into a catalog and map business terms to the dataset column headers. The business terms and their mappings are specified in a csv file included with the project. The user must first ensure that the catalog exists and the imported business terms have been published.\n\nThe user can also assign business terms to column headers manually or by using the Data Discovery capability within Cloud Pak for Data. \n\nThis notebook is optional. The analytics project runs as expected even if this notebook is not used. \n\n**Note that as only Admin users can import terms, this notebook should be run by an Admin user only.**"},{"metadata":{},"cell_type":"code","source":"# imports for the rest APIs interactions with WKC\nimport requests\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\nimport json\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\nfrom pandas.io.json import json_normalize\nimport pandas as pd\nimport os\n# use this library for reading and saving data in CP4D\nfrom project_lib import Project\nproject = Project()","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This project contains Sample Materials, provided under license. <br>\nLicensed Materials - Property of IBM. <br>\nÂ© Copyright IBM Corp. 2020. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.<br>**"},{"metadata":{},"cell_type":"markdown","source":"## Create Catalog\n\nThe dataset must first be published into a catalog. The catalog must be manually created. Under **Organize** in the navigation menu, select **All Catalogs** and select **New Catalog**. Enter the name for the catalog and the description if necessary and create the catalog. If the user has already created the catalog this step can be skipped and the existing catalog name should be specified in the code cell below.\n"},{"metadata":{},"cell_type":"markdown","source":"## User Inputs\n\nThe user must enter the following before running the rest of the notebook: \n1. **host :** host url of the cluster we are working on.\n2. **uname :** username for user on this cluster.\n3. **pword :** password for user on this cluster.\n4. **catalog_name :** Name of the catalog that we would like to publish the csv to. This catalog is created based on the instructions above or an existing catalog."},{"metadata":{},"cell_type":"code","source":"# sample input and syntax\n# host = 'https://xxxxx.com/'\n# uname = 'admin'\n# pword = '******'\n# catalog_name = 'name for the catalog'\n\nhost = '*******'\nuname = '*******'\npword = '*******'\ncatalog_name = '*******'","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also create additional variables. The user does not need to change the code cell below, unless they change the business terms category name or the name of the csv file with mappings.\n\n1. **parent_category :** Parent category of all the projects .i.e Industry Accelerators.\n2. **category_name :** Name of the business term category corresponding to the project.\n3. **terms_file :** Name of the csv file containing the list of mappings between column headers and business terms.\n3. **csv_file_to_publish :** Name of the csv file that will be published into the catalog and for which we map business terms."},{"metadata":{},"cell_type":"code","source":"parent_category = \"Industry Accelerators\"\ncategory_name = \"Utilities Customer Attrition Prediction\"\nterms_file = \"utilities customer attrition prediction map terms.csv\" \ncsv_file_to_publish = 'Attrition View.csv'","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a requests session and use the same session throughout the notebook. "},{"metadata":{},"cell_type":"code","source":"# Creates requests session and stores in `s`\ns = requests.Session()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Authentication"},{"metadata":{},"cell_type":"markdown","source":"Generate a token and validate the token on this cluster."},{"metadata":{},"cell_type":"code","source":"# Authenticate the cluster with specified username and password and store the access token for future reference\nwkcURLauth=host+\"icp4d-api/v1/authorize\"\n\n# Payload with username and password\npayload={\n    \"username\": uname,\n    \"password\": pword\n}\n\n# Header with json format\nheaders = {\n    'Content-Type': \"application/json\",\n    'cache-control': \"no-cache\"\n    }\n\n# Creates a post request with the endpoints specified above in the wkcURLauth variable with payload and header.\n# When successfully authenticated token is stored in a variable as below\n# catch error if the specified url is not correct\ntry:\n    res = s.post(wkcURLauth,headers=headers,json=payload, verify=False)\nexcept:\n    print(\"The below error has occurred. Please check that the hostname entered is correct.\")\n    raise\n    \nif res.status_code == 200:\n    accessToken=json.loads(res.text)['token']\nelse:\n    print('The below error has occurred. Please check entered username and password are correct.')\n    raise ValueError(res.text)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"code","source":"# This step is similar to above cell. The above request session requires cookie to be added.\n\nwkcURLauth=host+\"v1/preauth/signin\"\npayload={\n    \"username\": uname,\n    \"password\": pword\n}\n\nheaders = {\n    'Content-Type': \"application/json\",\n    'Authorization': \"Bearer \"+accessToken,\n    'Accept': \"*/*\",\n    'Cache-Control': \"no-cache\",\n    'Accept-Encoding': \"gzip, deflate\",\n    'Content-Length': \"56\",\n    'Connection': \"keep-alive\",\n    'cache-control': \"no-cache\"\n    }\nres = s.post(wkcURLauth,headers=headers,json=payload, verify=False)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set catalog cookies"},{"metadata":{},"cell_type":"markdown","source":"In order to access the catalogs, catalog cookies have to be set using the below endpoints. These cookies will be stored in the session variable created above."},{"metadata":{},"cell_type":"code","source":"# Below get request stores catalog cookie into the session\ncatalog_cookie=s.get(host+\"catalog/auth/iamid/callback?redirectUrl=/data/catalogs/&context=icp4data\",verify=False)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Map Business Terms to Headers\n\nWe complete the following steps to map the business terms to column headers:\n\n1. Check if the Parent Category, `Industry Accelerators`, and subcategory, `Utilities Customer Attrition Prediction`, exists.\n2. Load the business terms from the `Utilities Customer Attrition Prediction` subcategory into a dataframe.\n3. Publish the specified dataset into the catalog.\n4. Assign business terms to the dataset column headers."},{"metadata":{},"cell_type":"markdown","source":"### 1. Check Parent Category and Subcategory"},{"metadata":{},"cell_type":"markdown","source":"Below cell fetches all the categories present in the cluster and stores category id of the parent category `Industry Accelerators`."},{"metadata":{},"cell_type":"code","source":"# Endpoint to check all the categories in the server\nparent_url=host+\"gov/api/categories?limit=100\"\n# get request to fetch all categories\nparent_cat=s.get(parent_url,verify=False)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the parent category id:"},{"metadata":{},"cell_type":"code","source":"# Check if Industry accelerator category exists and load its id into a variable `parent_id`\nif parent_cat.status_code == 200:\n    parent_json=json.loads(parent_cat.text)\n    for i in parent_json['rows']:\n                if i['metadata']['name']== parent_category:\n                    print(\"Parent Category - \",parent_category,\"exists\")\n                    parent_id=i['artifact_id'] \n    if parent_json['size']==0:\n        print(\"The below error has occurred. \" + \"Please ensure that parent category '\" + parent_category + \"' exists and the user has sufficient permissions.\")\n        raise ValueError(parent_cat.text)\nelse:\n    print(\"The below error has occurred. \" + \"Please ensure that parent category, '\" + parent_category + \"', exists.\")\n    raise ValueError(parent_cat.text)","execution_count":9,"outputs":[{"output_type":"stream","text":"Parent Category -  Industry Accelerators exists\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Check if `Utilities Customer Attrition Prediction` subcategory exists within the `Industry Accelerators` category."},{"metadata":{},"cell_type":"code","source":"#Endpoint to get all the subcategories in Industry Accelerator\ncategory_url=host+\"gov/api/categories/children/\"+parent_id+\"?page=1&limit=100\"\n# get request to fetch all categories\nsubcategory=s.get(category_url,verify=False)","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"code","source":"if subcategory.status_code == 200:\n    subcategory_json=json.loads(subcategory.text)\n\n    # Check if required category exists and load its id into a variable `subcategory_id`\n    for i in subcategory_json['rows']:\n        if i['metadata']['name']== category_name:\n            print(\"Category - \",category_name,\"exists - Passed\")\n\n            exists_category=True\n            subcategory_id=i['artifact_id'] \nelse:\n    print(\"The below error has occurred. \" + \"Please ensure that category, '\" + category_category + \"', exists.\")\n    raise ValueError(subcategory.text)","execution_count":11,"outputs":[{"output_type":"stream","text":"Category -  Utilities Customer Attrition Prediction exists - Passed\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 2. Load Subcategory Business Terms into Dataframe "},{"metadata":{},"cell_type":"markdown","source":"Get all of the terms in the `Utilities Customer Attrition Prediction` subcategory and store them in the `df_terms` dataframe."},{"metadata":{},"cell_type":"code","source":"# Create a payload for the post request, This payload contains information on size of the terms, source, category and subcategory ids\npayload={\"size\":300,\"from\":0,\"_source\":[\"artifact_id\",\"metadata.artifact_type\",\"metadata.name\",\"metadata.description\",\"categories\",\"entity.artifacts\"],\"query\":{\"bool\":{\"filter\":{\"bool\":{\"minimum_should_match\":1,\"should\":[{\"term\":{\"categories.primary_category_id\":subcategory_id}},{\"term\":{\"categories.secondary_category_ids\":subcategory_id}}],\"must_not\":{\"terms\":{\"metadata.artifact_type\":[\"category\"]}}}}}}}\n# create a post request with above payload \nwf=s.post(host+\"v3/search\",headers=headers,json=payload,verify=False)\n# it will return all the terms , load these terms into a dataframe\nwf_json=json.loads(wf.text)['rows']\ndf_terms=json_normalize(wf_json)\n\ndf_terms=df_terms[['entity.artifacts.global_id','metadata.name']]","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"code","source":"# terms dataframe looks as below\ndf_terms.head()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                          entity.artifacts.global_id           metadata.name\n0  5d2d5419-0032-4c64-90e2-ce68c6997bb5_fc3bef7c-...               City Name\n1  5d2d5419-0032-4c64-90e2-ce68c6997bb5_72195706-...     Customer Identifier\n2  5d2d5419-0032-4c64-90e2-ce68c6997bb5_5cfdfeef-...     Customer Importance\n3  5d2d5419-0032-4c64-90e2-ce68c6997bb5_06991e34-...  Fraud Reporting Source\n4  5d2d5419-0032-4c64-90e2-ce68c6997bb5_cdbb6181-...        Transaction Date","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity.artifacts.global_id</th>\n      <th>metadata.name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_fc3bef7c-...</td>\n      <td>City Name</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_72195706-...</td>\n      <td>Customer Identifier</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_5cfdfeef-...</td>\n      <td>Customer Importance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_06991e34-...</td>\n      <td>Fraud Reporting Source</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_cdbb6181-...</td>\n      <td>Transaction Date</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 3. Publish Dataset into Catalog"},{"metadata":{},"cell_type":"markdown","source":"Get the ID of the catalog that was specified in the user inputs at the beginning of this notebook."},{"metadata":{},"cell_type":"code","source":"## Get catalog that created and its id by providing name of the catalog created, wich should be same as the one entered in the previous cells\n\n# Create new header for the requests\nheaders = {\n'Content-Type': \"application/json\",\n'Authorization': \"Bearer \"+accessToken\n\n}\n\n# endpoint to get all the catalogs \nget_catalog=s.get(host+\"v2/catalogs/\",verify=False, headers=headers)\n\n## Find the catalog created with specific name and store name and id of it into catalog_name and catalog_id respectively\ntry:\n    get_catalog_json=json.loads(get_catalog.text)['catalogs']\nexcept:\n    print(\"The below error has occurred. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n    raise\n    \ncatalog_id = ''\nfor metadata in get_catalog_json:\n    if metadata['entity']['name']==catalog_name:\n        catalog_id=metadata['metadata']['guid']\n        print(\"catalog_id for\",catalog_name, catalog_id)\n\nif catalog_id == '':\n    print(\"The provided catalog name cannot be found. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n    raise ValueError(\"Catalog cannot be found\")","execution_count":14,"outputs":[{"output_type":"stream","text":"catalog_id for db_catalog dc66bf0e-2166-4ecc-9df0-95b3baf2cbd6\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Get the project id. All project assets can be accessed using this project id."},{"metadata":{},"cell_type":"code","source":"project_id=os.environ['PROJECT_ID']","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get all existing csv files in the project folder and store the names of these files. "},{"metadata":{},"cell_type":"code","source":"# payload \npayload={\"query\":\"*:*\",\"limit\":200}\n# endpoint to access all the project assets in the project folder \nasset_url=host+\"v2/asset_types/asset/search?project_id=\"+project_id\nget_asset=s.post(asset_url,json=payload,verify=False)","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we get the asset id of the dataset to be published to the catalog."},{"metadata":{},"cell_type":"code","source":"# Get asset ids of all csv files to be published in to the catalog and store the asset ids in an array\n\nproject_asset_id=[]\n# Payload to query all project assets\npayload={\"query\":\"*:*\",\"limit\":200}\n\nget_asset=s.post(host+\"v2/asset_types/asset/search?project_id=\"+project_id,json=payload,verify=False, headers=headers)\nget_asset_json=json.loads(get_asset.text)\nfor j in get_asset_json['results']:\n    if j['metadata']['name']==csv_file_to_publish:\n        print(\"Asset id of\",csv_file_to_publish,\":\",j['metadata']['asset_id'])\n        project_asset_id.append(j['metadata']['asset_id'])","execution_count":17,"outputs":[{"output_type":"stream","text":"Asset id of Attrition View.csv : 5066a9ac-f6a3-43e8-86bd-cfcf9c88aa85\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Using the asset ID for the dataset, upload the dataset into the catalog using the post request below. Get the new asset ID of the newly published dataset."},{"metadata":{},"cell_type":"code","source":"print(\"ASSET ID's of the published assets\")\n# Creates a empty dictionary\ncatalog_asset_ids={}\nfor asset_id in project_asset_id:\n    #for  each asset in the project , publish them into the catalog \n    # pyload to publish the asset\n    payload={\"mode\":0,\"catalog_id\":catalog_id,\"metadata\":{}}\n    # endpoint to publish asset\n    asset_publish_url=host+\"v2/assets/\"+asset_id+\"/publish?project_id=\"+project_id\n    # Post request with endpoint, heaeder and payload\n    publishasset=requests.post(asset_publish_url,json=payload,headers=headers,verify=False)\n    # api endpoint returns below text\n    publishasset_json=json.loads(publishasset.text)\n    # extract csv file published and its asset id and append it to the dictionary\n    catalog_asset_ids[publishasset_json['metadata']['name']]=publishasset_json['asset_id']\n    \nprint(catalog_asset_ids)","execution_count":18,"outputs":[{"output_type":"stream","text":"ASSET ID's of the published assets\n{'Attrition View.csv': '3eee3244-e528-4e1e-b439-8af2651dcd12'}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 4. Assign Business Terms to Column Headers\n\nRead in the file with business terms and their associated column headers and view a sample of the data."},{"metadata":{},"cell_type":"code","source":"my_file = project.get_file(terms_file)\nmy_file.seek(0)\nmap_terms = pd.read_csv(my_file)","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"code","source":"# comment out below set of codes if the map terms csv has additional spaces which need to be truncated.\n#map_terms['Column_header']=map_terms['Column_header'].str.strip(' ')\n#map_terms[\"Business Terms\"]=map_terms[\"Business Terms\"].str.strip(' ')\n#map_terms[\"File\"]=map_terms[\"File\"].str.strip(' ')\n#map_terms[\"Table\"]=map_terms[\"Table\"].str.strip(' ')\n\n# Specify the name of the table we are working on\n#map_terms=map_terms[map_terms['Table']==table_name]\nprint(map_terms.shape)\nmap_terms.head()","execution_count":20,"outputs":[{"output_type":"stream","text":"(65, 4)\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"               Business Terms Column_header  \\\n0              Account Number    ACCOUNT_ID   \n1  Address Line 1 Description      APPT_NBR   \n2     Car Ownership Indicator  IS_CAR_OWNER   \n3                   City Name          CITY   \n4          Communication Type      ISSUE_CD   \n\n                               Table            File  \n0  ENERGY and UTILITIES ACCELERATORS  Attrition View  \n1  ENERGY and UTILITIES ACCELERATORS  Attrition View  \n2  ENERGY and UTILITIES ACCELERATORS  Attrition View  \n3  ENERGY and UTILITIES ACCELERATORS  Attrition View  \n4  ENERGY and UTILITIES ACCELERATORS  Attrition View  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Business Terms</th>\n      <th>Column_header</th>\n      <th>Table</th>\n      <th>File</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Account Number</td>\n      <td>ACCOUNT_ID</td>\n      <td>ENERGY and UTILITIES ACCELERATORS</td>\n      <td>Attrition View</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Address Line 1 Description</td>\n      <td>APPT_NBR</td>\n      <td>ENERGY and UTILITIES ACCELERATORS</td>\n      <td>Attrition View</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Car Ownership Indicator</td>\n      <td>IS_CAR_OWNER</td>\n      <td>ENERGY and UTILITIES ACCELERATORS</td>\n      <td>Attrition View</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>City Name</td>\n      <td>CITY</td>\n      <td>ENERGY and UTILITIES ACCELERATORS</td>\n      <td>Attrition View</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Communication Type</td>\n      <td>ISSUE_CD</td>\n      <td>ENERGY and UTILITIES ACCELERATORS</td>\n      <td>Attrition View</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"code","source":"df_terms.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"                          entity.artifacts.global_id           metadata.name\n0  5d2d5419-0032-4c64-90e2-ce68c6997bb5_fc3bef7c-...               City Name\n1  5d2d5419-0032-4c64-90e2-ce68c6997bb5_72195706-...     Customer Identifier\n2  5d2d5419-0032-4c64-90e2-ce68c6997bb5_5cfdfeef-...     Customer Importance\n3  5d2d5419-0032-4c64-90e2-ce68c6997bb5_06991e34-...  Fraud Reporting Source\n4  5d2d5419-0032-4c64-90e2-ce68c6997bb5_cdbb6181-...        Transaction Date","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity.artifacts.global_id</th>\n      <th>metadata.name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_fc3bef7c-...</td>\n      <td>City Name</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_72195706-...</td>\n      <td>Customer Identifier</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_5cfdfeef-...</td>\n      <td>Customer Importance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_06991e34-...</td>\n      <td>Fraud Reporting Source</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_cdbb6181-...</td>\n      <td>Transaction Date</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Join the `df_terms` and `map_terms` dataframes and map each column header to a business term. The code below loops through each file in the catalog (one file in our case) and performs the following tasks:\n\n1. Create a dataframe with column headers in the catalog and associated business term and term ids.\n2. Fetch catalog asset id for each csv in the catalog.\n3. Create a column_info attribute for all the files in the catalog.\n4. Map column header to the business terms. "},{"metadata":{},"cell_type":"code","source":"# For every file in the map terms csv do the following\n# Join the csv with specified file name with the published terms to get its term id\n# drop if any duplicates found to avoid multiple mappings for the same term\n\n#map_terms=map_terms[map_terms['File']==file]\nmap_terms=map_terms.sort_values(by=['File','Column_header'])\nTerms_Headers=pd.merge(map_terms,df_terms,left_on='Business Terms',right_on='metadata.name',how='inner')\nTerms_Headers=Terms_Headers.drop_duplicates()\n\nfor file in catalog_asset_ids:#map_terms.File.unique():\n    # Catalog asset id of the particular csvs\n    # for each file name in the map_terms if the csv with this file name exists, get its asset_id from the catalog and use the post request publish create column_info attribute\n    # This column info attribute is necessary to map the busines terms to column to header\n    \n\n    catalog_asset_id=catalog_asset_ids[file]\n    print(file,  catalog_asset_id)\n    #### \n    payload={\"name\": \"column_info\",\n       \"entity\":{\n                  #\"sample_size\":50\n               }\n    }\n    t=requests.post(host+\"v2/assets/\"+catalog_asset_id+\"/attributes?catalog_id=\"+catalog_id,json=payload,headers=headers,verify=False)\n    #print(t.text)\n    # For each column header in the file map its corresponding business term retrieved from the above join in the dataframe\n\n    i=0\n    for index, rows in Terms_Headers.iterrows(): \n        i+=1\n        print(i,rows.Column_header.strip(), \"is mapped to\", rows['Business Terms'])\n        # Create list for the current row \n        # Below payload is used for the patch request to map the  header to business terms\n        payload=[{\"op\":\"add\",\"path\":\"/\"+rows.Column_header.strip(),\"value\":{\"column_terms\":[{\"term_display_name\":rows['Business Terms'],\"term_id\":rows[\"entity.artifacts.global_id\"]}]},\"attribute\":\"column_info\"}]\n    #\n        # Endpoint for patch request\n        url=host+\"v2/assets/\"+catalog_asset_id+\"/attributes/column_info?catalog_id=\"+catalog_id\n    # patch request to map busines terms to column header using term_id\n        patch_attribute=s.patch(url,json=payload,headers=headers,verify=False)\n    #\n        json.loads(patch_attribute.text) ","execution_count":22,"outputs":[{"output_type":"stream","text":"Attrition View.csv 3eee3244-e528-4e1e-b439-8af2651dcd12\n1 ACCOUNT_ID is mapped to Account Number\n2 ADDRESS is mapped to Postal Address\n3 AGE is mapped to Date Of Birth\n4 DATE_OF_BIRTH is mapped to Date Of Birth\n5 APPT_NBR is mapped to Address Line 1 Description\n6 ATTRITION_STATUS is mapped to Customer Attrition Rate\n7 CALL_CENTER_RESPONSE is mapped to Customer Communication\n8 EMAIL_RESPONSE is mapped to Customer Communication\n9 SMART_METER_COMMENTS is mapped to Customer Communication\n10 CITY is mapped to City Name\n11 CLTV is mapped to Customer Lifetime Value\n12 CLTV_RATIO is mapped to Customer Lifetime Value\n13 CLTV_RATIO is mapped to Customer Acquisition Cost\n14 COMPLAINTS is mapped to Customer Complaints\n15 ISSUE is mapped to Customer Complaints\n16 ISSUE_CD is mapped to Customer Complaints\n17 ISSUE_ID is mapped to Customer Complaints\n18 CREDIT_RATING is mapped to Customer Credit Authority Level\n19 CST_SEGMENT_ID is mapped to Customer Market Segment\n20 CURRENT_CONTRACT_ID is mapped to Customer Agreement Number\n21 CURRENT_OFFER_ID is mapped to Product Offer\n22 CUSTOMER_ID is mapped to Customer Identifier\n23 CUSTOMER_TYPE is mapped to Customer Type\n24 EBILL is mapped to Electronic Bill Indicator\n25 EDUCATION is mapped to Education Level\n26 EDUCATION_CD is mapped to Education Level\n27 EDUCATION_ID is mapped to Education Level\n28 EMAIL is mapped to Email Address\n29 EMPLOYMENT is mapped to Employment Status\n30 EMPLOYMENT_CD is mapped to Employment Status\n31 EMPLOYMENT_ID is mapped to Employment Status\n32 ENERGY_USAGE_PER_MONTH is mapped to Energy Usage Per Month\n33 FIRST_NAME is mapped to First Name\n34 GENDER is mapped to Gender\n35 GENDER_CD is mapped to Gender\n36 GENDER_ID is mapped to Gender\n37 HAS_DISCOUNT_PACKAGE is mapped to Discount\n38 HAS_EV is mapped to Electric Vehicle Indicator\n39 HAS_HOME_AUTOMATION is mapped to Home Automation Indicator\n40 HAS_PV is mapped to Photovoltaic System Indicator\n41 HAS_THERMOSTAT is mapped to Thermostat Indicator\n42 HAS_WIND is mapped to Wind Energy Indicator\n43 IN_WARRANTY is mapped to Product Warranty Indicator\n44 ISSUE_CD is mapped to Communication Type\n45 IS_CAR_OWNER is mapped to Car Ownership Indicator\n46 IS_REGISTERED_FOR_ALERTS is mapped to Registered For Alerts Indicator\n47 LAST_NAME is mapped to Last Name\n48 MARITAL_STATUS is mapped to Marital Status\n49 MARITAL_STATUS_ID is mapped to Marital Status\n50 MEDIAN_YRLY_USAGE_CUR_YEAR_MINUS_1 is mapped to Standard Yearly Usage\n51 STD_YRLY_USAGE_CUR_YEAR_MINUS_1 is mapped to Standard Yearly Usage\n52 STD_YRLY_USAGE_CUR_YEAR_MINUS_2 is mapped to Standard Yearly Usage\n53 STD_YRLY_USAGE_CUR_YEAR_MINUS_3 is mapped to Standard Yearly Usage\n54 STD_YRLY_USAGE_CUR_YEAR_MINUS_4 is mapped to Standard Yearly Usage\n55 STD_YRLY_USAGE_CUR_YEAR_MINUS_5 is mapped to Standard Yearly Usage\n56 STD_YRLY_USAGE_CUR_YEAR_MINUS_6 is mapped to Standard Yearly Usage\n57 STD_YRLY_USAGE_CUR_YEAR_MINUS_7 is mapped to Standard Yearly Usage\n58 OWNS_HOME is mapped to Household Home Ownership\n59 PHONE_1 is mapped to Telephone Number\n60 PHONE_2 is mapped to Telephone Number\n61 PV_ZONING is mapped to Photovoltaic Zone Indicator\n62 SMART_METER_COMMENTS is mapped to Smart Meter Indicator\n63 TENURE is mapped to Customer Tenure\n64 WIND_ZONING is mapped to Wind Zone Indicator\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The specified dataset is now published to the catalog and its column headers are mapped to their associated business terms. \n\nNavigate to below path to verify the mappings created above. <br>\n\n**All Catalogs --> New Catalog --> csv file --> any column header from the above list**.\n\nThe associated business term for the column header is displayed."},{"metadata":{},"cell_type":"code","source":"s.close()","execution_count":23,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.6","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}