{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Create and Test Scoring Pipeline and Deploy R Shiny Dashboard App"},{"metadata":{},"cell_type":"markdown","source":"### Introduction\n\nNow that we have built the machine learning pipeline, stored and deployed it, we can use the pipeline to ingest new data, prep it and score it. \n\nIn the first part of the notebook we will:\n\n* Programmatically get the ID's for the deployment space and model deployment that were created in the **1-model_training** notebook.\n* Create a deployable function which will take raw data for scoring, complete the initial prep, feed it to the pipeline and score it.\n* Deploy the function.\n* Create the required payload, invoke the deployed function and return predictions.\n\nIn the second part we will:\n* Store Shiny assets into the same deployment space.\n* Deploy Shiny assets as an app and view the dashboard"},{"metadata":{},"cell_type":"markdown","source":"**Sample Materials, provided under license. <br>\nLicensed Materials - Property of IBM. <br>\nÂ© Copyright IBM Corp. 2020. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. <br>**"},{"metadata":{},"cell_type":"code","source":"import os\nimport pandas as pd\nimport datetime\n\n\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"openshift\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"3.0.0\"\n}\n\n\nclient = WatsonMachineLearningAPIClient(wml_credentials)\n\n# use this library for reading and saving data in CP4D\nfrom project_lib import Project\nproject = Project()","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set up Deployment Space, Deployments and Assets\n\nThe following code programmatically gets the deployment space and the model deployment details which were created in 1-model_training. \n We use the space name and default tags that were used when creating the deployments as specified below. If multiple spaces with the same name exist, the code will take the space that was created most recently. Similarly, if multiple deployments within the selected space have the same tag, the most recently created deployment is used.\n\n\nAlternatively, the user can manually enter the space and deployment guid's.\n\nThe code also promotes an asset into the deployment space. Before passing data to the pipeline, we completed one step of prepping the data, we aggregated some categories that had a low number of cases. This step needs to be completed when scoring any new data. We saved the category names that were aggregated out into a json file, `metadata.json`. We promote this asset into the deployment space. By promoting the asset into the deployment space, it is available and can be accessed by the deployed function."},{"metadata":{},"cell_type":"code","source":"\nspace_name = 'Utilities Customer Attrition Space'\nmodel_tag = 'utilities_attrition_pipeline_tag'\ndeployment_tag = 'utilities_attrition_deployment_tag'","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the space we are working in, which is found using the name that was hardcoded in **1-model_training**. If there are multiple spaces with the same name, we take the one that was created most recently. \n\nIf the user would like to use a different space manually set the space_id.\n\nSet the space as the default space for working."},{"metadata":{},"cell_type":"code","source":"l_space_details = []\nl_space_details_created_times = []\nfor space_details in client.spaces.get_details()['resources']:\n    if space_details['entity']['name'] == space_name:\n        l_space_details.append(space_details)\n        l_space_details_created_times.append(datetime.datetime.strptime(space_details['metadata']['created_at'],  '%Y-%m-%dT%H:%M:%S.%fZ'))\n        \n# get the index of the latest created date from the list and use that to get the space_id\nlist_latest_index = l_space_details_created_times.index(max(l_space_details_created_times))\nspace_id = l_space_details[list_latest_index]['metadata']['guid']\n# set this space as default space\nclient.set.default_space(space_id)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'SUCCESS'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Get the deployment id, again, found using the tags that were hardcoded. If there are multiple deployments with the same tag in the same space, we take the latest."},{"metadata":{},"cell_type":"code","source":"l_deployment_details = []\nl_deployment_details_created_times = []\nfor deployment in client.deployments.get_details()['resources']:\n    if 'tags' in deployment['entity']:\n        if deployment['entity']['tags'][0]['value'] == deployment_tag:            \n            l_deployment_details.append(deployment)\n            l_deployment_details_created_times.append(datetime.datetime.strptime(deployment['metadata']['created_at'],  '%Y-%m-%dT%H:%M:%S.%fZ'))\n\n# get the index of the latest created date from the list and use that to get the deployment_id\nlist_latest_index = l_deployment_details_created_times.index(max(l_deployment_details_created_times))\ndeployment_id = l_deployment_details[list_latest_index]['metadata']['guid']","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create the Deployable Function\n\nFunctions can be deployed in Watson Machine Learning in the same way models can be deployed. The python client or REST API can be used to send data to the deployed function. Using the deployed function allows us to prepare the data and pass it to the pipeline for scoring all within the deployed function.\n\nWe start off by creating the dictionary of default parameters to be passed to the function. We get the ID of the asset that has been promoted into the deployment space. We also add the model deployment ID and space ID into the dictionary."},{"metadata":{},"cell_type":"code","source":"# create the wml_credentials again. After already creating the client using the credentials, the instance_id gets updated to 999\n# update the value\nwml_credentials[\"instance_id\"] = \"openshift\"\n\nai_parms = {'wml_credentials' : wml_credentials, 'space_id' : space_id, 'model_deployment_id' : deployment_id}","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Scoring Pipeline Function\n\nThe function below takes a dictionary of raw data to be scored as a payload. Any aggregation on categorical columns that are required is completed before the data is passed to the deployed pipeline. The pipeline completes the remaining steps in prepping the data, passes the data to the model and returns the predicted class and probabilities for attrition."},{"metadata":{},"cell_type":"code","source":"def scoring_pipeline(parms=ai_parms):\n    \n    from watson_machine_learning_client import WatsonMachineLearningAPIClient\n    client = WatsonMachineLearningAPIClient(parms[\"wml_credentials\"])\n    client.set.default_space(parms['space_id'])    \n\n    def score(payload):\n        import json\n        import requests\n        import pandas as pd\n     \n        extracted_payload = payload['input_data'][0]['values']\n        \n        # the data passed in from the r shiny app will be in string format\n        # convert to json s we can read it into a dataframe\n        if isinstance(extracted_payload, str):\n            # we need to remove the \\ from the string\n            extracted_payload = extracted_payload.replace('\\\\', '')\n            extracted_payload = json.loads(extracted_payload)\n        \n        # create the dataframe from the values and fields that have been passed in the payload\n        df = pd.DataFrame(extracted_payload)\n        \n        l_customer_ids = df['CUSTOMER_ID'].tolist()\n        \n        metadata_dict = client.deployments.get_details(parms['model_deployment_id'])['entity']['custom']          \n        \n        grouping_dict = metadata_dict['grouping_cols']\n        # loop through each key in the dictionary, which is the name of a column that needs some aggregation \n        for key, value_dict in grouping_dict.items():    \n            df[key].replace(value_dict, inplace=True)\n            \n        # all other prep steps are handled by the pipeline - columns not needed are removed, missing values are replaced\n        # get the deployment and score the data      \n        scoring_payload = {\"input_data\":  [{ \"values\" : df.values.tolist()}]}\n        predictions = client.deployments.score(parms['model_deployment_id'], scoring_payload)\n        \n        # update the predicted class returned based on our threshold\n        # by default the predicted class is based on 0.5 probability, we changed this based on ROC curve\n        for idx, val in enumerate(predictions['predictions'][0]['values']):\n            if predictions['predictions'][0]['values'][idx][1][1] >= metadata_dict['probability_threshold']:\n                predictions['predictions'][0]['values'][idx][0] = 1\n            else:\n                predictions['predictions'][0]['values'][idx][0] = 0\n            \n            \n        return {\"predictions\" : [{'values' : predictions, 'customer_ids' : l_customer_ids}]}\n            \n    return score","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deploy the Function\n\nThe user can specify the name of the function and deployment in the code below. As we have previously seen, we use tags in the metadata to allow us to programmatically identify the deployed function."},{"metadata":{},"cell_type":"code","source":"# store the function and deploy it \nfunction_name = 'attrition_scoring_pipeline_function'\nfunction_deployment_name = 'attrition_scoring_pipeline_function_deployment'","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Get the ID of software specification to be used with the function\n\nThe Software Specification refers to the runtime used in the Notebook, WML training and WML deployment. It contains details about the runtime platform, framework versions, other packages used and any custom library used in the concerned runtime.\n\nOur notebooks use the `default_py3.6` software specification. When we deploy our function we want it to have the same software specification as the notebooks. We get the ID of the notebook software specification and include it in the metadata when storing the function."},{"metadata":{},"cell_type":"code","source":"default_software_spec_id = client.software_specifications.get_uid_by_name(\"default_py3.6\")","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"code","source":"# add the metadata for the function and deployment    \nmeta_data = {\n    client.repository.FunctionMetaNames.NAME : function_name,\n    client.repository.FunctionMetaNames.TAGS : [{'value' : 'utilities_attrition_scoring_pipeline_function_tag'}],\n    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: default_software_spec_id,\n    client.repository.FunctionMetaNames.SPACE_UID: space_id\n}\n\nfunction_details = client.repository.store_function(meta_props=meta_data, function=scoring_pipeline)\n\nfunction_id = function_details[\"metadata\"][\"guid\"]\n\nmeta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: function_deployment_name,\n    client.deployments.ConfigurationMetaNames.TAGS : [{'value' : 'utilities_attrition_scoring_pipeline_function_deployment_tag'}],\n    client.deployments.ConfigurationMetaNames.ONLINE: {},\n    client.deployments.ConfigurationMetaNames.SPACE_UID: space_id\n}\n\n# deploy the stored model\nfunction_deployment_details = client.deployments.create(artifact_uid=function_id, meta_props=meta_props)","execution_count":10,"outputs":[{"output_type":"stream","text":"\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '5d79f652-c2fe-4d31-a2cc-1ca2fcf733f2' started\n\n#######################################################################################\n\n\ninitializing......\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='def8ed3e-fbcc-4cb1-9428-7438b1e44338'\n------------------------------------------------------------------------------------------------\n\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Score New Data\n\nTo create the payload, we pass a dictionary with raw data as the function payload. For demonstration purposes we will use the same csv file that was used in **1-model_training** notebook as the raw data. We take 5 records and convert them into a dictionary form to be passed to the payload.  \n\nWe then get the guid of the deployed function and use the python client to score the data. The deployed function returns the classification prediction along with the probabilities. "},{"metadata":{},"cell_type":"code","source":"# specify the name of the csv file with raw customer data that we would like to score for\ndataset_name = 'Attrition View.csv'\n\nmy_file = project.get_file(dataset_name)\nmy_file.seek(0)\ndf_raw_data = pd.read_csv(my_file)\n\n# remove the target variable so the data has the same inputs as training data\ndf_raw_data.drop('ATTRITION_STATUS', axis=1, inplace=True)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"code","source":"payload_input_dict = df_raw_data.head(5).to_dict(orient='records')","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the payload, not all of these fields are used in the model, transformers and pipeline will take care of removing columns that aren't used."},{"metadata":{},"cell_type":"code","source":"payload_input_dict[1]","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"{'CUSTOMER_ID': 2,\n 'GENDER_ID': 1,\n 'FIRST_NAME': 'Ima',\n 'LAST_NAME': 'Labadie',\n 'PHONE_1': '505-339-5197',\n 'EMAIL': 'Ima.Labadie@allie.tv',\n 'AGE': 34,\n 'ENERGY_USAGE_PER_MONTH': 4970,\n 'ENERGY_EFFICIENCY': 0.35600000000000004,\n 'IS_REGISTERED_FOR_ALERTS': 0,\n 'OWNS_HOME': 1,\n 'COMPLAINTS': 1,\n 'HAS_THERMOSTAT': 1,\n 'HAS_HOME_AUTOMATION': 0,\n 'PV_ZONING': 1,\n 'WIND_ZONING': 0,\n 'SMART_METER_COMMENTS': 'Negative',\n 'IS_CAR_OWNER': 1,\n 'HAS_EV': 0,\n 'HAS_PV': 0,\n 'HAS_WIND': 0,\n 'TENURE': 11,\n 'EBILL': 0,\n 'IN_WARRANTY': 1,\n 'CITY': 'Mountain View',\n 'CURRENT_OFFER': 'Free Energy Audits',\n 'CURRENT_CONTRACT': 'Dynamic Pricing 240 minute plan',\n 'CURRENT_ISSUE': 'Billing Issue',\n 'MARITAL_STATUS': 'U',\n 'EDUCATION': \"Bachelor's degree\",\n 'SEGMENT': 'GOLD',\n 'EMPLOYMENT': 'Employed full-time',\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_1': 52098,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_2': 40740,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_3': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_4': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_5': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_6': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_7': 21481,\n 'MEDIAN_YRLY_USAGE_CUR_YEAR_MINUS_1': 20500}"},"metadata":{}}]},{"metadata":{},"cell_type":"code","source":"scoring_deployment_id = client.deployments.get_uid(function_deployment_details)\n\npayload = [{'values' : payload_input_dict}]\n\npayload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload}\n# score\nfunct_output = client.deployments.score(scoring_deployment_id, payload_metadata)\nfunct_output","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"{'predictions': [{'values': {'predictions': [{'fields': ['prediction',\n       'probability'],\n      'values': [[0, [0.8085850664760637, 0.19141493352393651]],\n       [1, [0.2273804809663913, 0.7726195190336088]],\n       [0, [0.780502232264842, 0.21949776773515772]],\n       [1, [0.3863743779099732, 0.6136256220900268]],\n       [1, [0.604246298971217, 0.39575370102878316]]]}]},\n   'customer_ids': [1, 2, 3, 4, 5]}]}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Deploy Shiny App"},{"metadata":{},"cell_type":"markdown","source":"In this section we will complete the steps to deploy a Shiny Dashboard in Cloud Pak for Data. The app can be deployed in a similar way to models and functions, using the watson_machine_learning_client package.\n\nAll of the files associated with the dashboard are contained in a zip file which is stored in data assets. If the user would like to make changes to the dashboard, they can download the zip from data assets and upload it in the RStudio IDE. "},{"metadata":{},"cell_type":"code","source":"r_shiny_deployment_name='Utilities_Customer_Attrition_Shiny_App'","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Store the App\n\nCreate the associated metadata and store the dashboard zip file in the deployment space. "},{"metadata":{},"cell_type":"code","source":"# Meta_props to store assets in space \nmeta_props = {\n    client.shiny.ConfigurationMetaNames.NAME: \"Utilities_Customer_Attrition_Shiny_assets\",\n    client.shiny.ConfigurationMetaNames.DESCRIPTION: 'Store shiny assets in deployment space' # optional\n}\napp_details = client.shiny.store(meta_props, '/project_data/data_asset/utilities-customer-attrition-prediction-analytics-dashboard.zip')","execution_count":9,"outputs":[{"output_type":"stream","text":"Creating Shiny asset...\nSUCCESS\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Deploy the App\n\nCreate the metadata for the Shiny deployment by providing  name, description, R-Shiny options and Hardware specifications. R-Shiny configuration provides options on whom you want to share the dashboard with, they are 1) anyone with the link 2) Authenticated users 3) Collaborators in this deployment space"},{"metadata":{},"cell_type":"code","source":"# Deployment metadata.\ndeployment_meta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: r_shiny_deployment_name,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: 'Deploy Utilities Customer Attrition dashboard',\n    client.deployments.ConfigurationMetaNames.R_SHINY: { 'authentication': 'anyone_with_url' },\n    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: { 'name': 'S', 'num_nodes': 1}\n}\n\n# Create the deployment.\napp_uid = client.shiny.get_uid(app_details)\nrshiny_deployment = client.deployments.create(app_uid, deployment_meta_props)","execution_count":10,"outputs":[{"output_type":"stream","text":"\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'b50cc4b6-0540-4bb5-9b0e-20916f5f2fa1' started\n\n#######################################################################################\n\n\ninitializing......\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='e50884be-3630-45b9-9be1-d8fc98d9fc1d'\n------------------------------------------------------------------------------------------------\n\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Launch Shiny App\nNow that the dashboard is deployed, it can be accessed through the web browser. The app URL can be found by navigating to the deployed app in the deployment space. \n\nOpen the Navigation Menu, under ***Analytics*** select ***Analytics deployments -> Utilities Customer Attrition Space -> Deployments -> Utilities_Customer_Attrition_Shiny_App*** to find the dashboard URL.\n\nAlternatively, the path for the app URL can be found from the deployment metadata created in the previous cell. This path should be appended to the user's Cloud Pak for Data hostname to get the complete app URL. To get the path, run the cell below:"},{"metadata":{},"cell_type":"code","source":"print(\"{HOSTNAME}\"+rshiny_deployment['metadata']['href'] + '/r_shiny')","execution_count":11,"outputs":[{"output_type":"stream","text":"{HOSTNAME}/v4/deployments/e50884be-3630-45b9-9be1-d8fc98d9fc1d/r_shiny\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.6","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}