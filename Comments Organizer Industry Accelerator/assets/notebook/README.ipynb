{"cells": [{"metadata": {"id": "1a151d07-a1a9-4c88-b27c-c30e9b6ffe50"}, "cell_type": "markdown", "source": "# Industry Accelerators - Comments Organizer"}, {"metadata": {"id": "515f58b5-ab33-4fcc-a115-087c19ae2dcf"}, "cell_type": "markdown", "source": "### Introduction\n\nThe accelerator includes a structured glossary of business terms and a set of sample data science assets. Your data scientists can use the sample notebooks, predictive models, and dashboards to accelerate data preparation, machine learning modeling, and data reporting. The provided sample application will be able to automatically group comments/feedback from customers as well as highlight positive and negative sentiment of the comments. This application could be used in the Retail Industry and would allow a central place for retailers to easily review customer feedback in an organized manner. \n\n#### Usage\n\n- Automatically and dynamically group comments by topics\n    - Simultaneously view sentiment analysis of the groups\n- View positive, negative, and neutral comments as well as the sentiment of comment's sentences"}, {"metadata": {"id": "0866b39a-e7b0-4ce2-b11c-557726ea62d1"}, "cell_type": "code", "source": "from IPython.display import display, Image\ndisplay(Image(filename='/project_data/data_asset/acceleratorWorkflow.png'))", "execution_count": null, "outputs": []}, {"metadata": {"id": "e3599992-fe62-4eab-a02f-69cf24cced8e"}, "cell_type": "markdown", "source": "# Inventory of Artifacts provided\n\n### Sample Datasets\n\nThe sample input dataset is obtained from [Data Asset eXchange](https://developer.ibm.com/exchanges/data/)\n\n- thematic-clustering-of-sentences/ : contains the dataset, dataset.csv, from IBM research described in their [paper](https://www.aclweb.org/anthology/P18-2009.pdf), used for clustering.\n- sentiment-composition-lexicons/ : contains all the datasets (ADJECTIVES.xlsx, LEXICON_UG.txt, LEXICON_BG.txt, SEMANTIC_CLASSES.xlsx) from IBM research described in their [paper](https://www.aclweb.org/anthology/C18-1189.pdf), used for sentiment analysis.\n\nMore information about the thematic clustering dataset can be found [here](https://developer.ibm.com/exchanges/data/all/thematic-clustering-of-sentences/). More information about the lexicons dataset can be found [here](https://developer.ibm.com/exchanges/data/all/sentiment-composition-lexicons/). \n\nCheck `thematic-clustering-glossary-terms.csv`, `adjectives-gloassary-terms.csv`, `lexicon-bg-glossary-terms.csv`, `lexicon-ug-glossary-terms.csv`, `semantic-classes-glossary-terms.csv` for data glossary"}, {"metadata": {"id": "68a49bc8-3f2a-4803-9862-6e50f5198057"}, "cell_type": "markdown", "source": "### Notebooks"}, {"metadata": {"id": "9b2198a6-df14-4745-a012-7273de1ac98f"}, "cell_type": "markdown", "source": "Follow the sequence shown below\n\n* **1_Data_Exploration_and_Model_Training**: Load data; Prepare and clean data for model training; Demonstrates in detail how the clustering and sentiment analysis models work;\n\n* **2_Model_Deployment**: Create a Watson Machine Learning based deployment space; Create and deploy pipeline functions for model scoring (one for clustering, another for sentiment analysis);"}, {"metadata": {"id": "2129beb6-1a37-42d0-9869-76b9b8bb92d6"}, "cell_type": "markdown", "source": "## Sequence of steps to run\n\n\n* Open **1_Data_Exploration_and_Model_Training** notebook & execute step-by-step to understand how the models work.\n* Open **2_Model_Deployment** notebook & execute step-by-step to deploy the models.\n* Go to `Deployments` and choose `Comments Organizer Space`. Click on `Deployments` tab and choose recent `Sentiment Analysis Deployment` and `Clustering Deployment`.\n* Under the `API Reference` tab, copy the endpoint link of both the deployments. This will be used for running the app locally.\n* View instructions under **Python Flask App** section to run the example app locally or deploy"}, {"metadata": {"id": "30d16963-bf84-4876-acea-5cdd38394a5d"}, "cell_type": "markdown", "source": "### Python Flask App\n\n#### Files\n* */comments_organizer_app*: Directory that contains all files for a Flask app, as well as files needed if want to deploy app\n  * */static*: Directory that contains static files like css, js (javascript) files needed for the front end of the app. Also has an example input for comments (test_comment_5.txt, test_comment_20.txt)\n  * */template*: Directory that contains any html files. index.html is the main file.\n  * *Profile*: File that contains command to run app, needed to deploy app on IBM Cloud Foundry\n  * *app.py*: Main Flask app file\n  * *manifest.yml*: Contains information needed to deploy the app on IBM Cloud Foundry\n  * *requirements.txt*: Python libraries and versions used in the app. If more libraries are used, this file should be updated to include them.\n  * *setup.py*: Setup for Flask app and deploying the app.\n\n\n#### Running the App Locally\nThe app serves as an example of using the functions deployed with Watson Machine Learning.\n\n1. In order to run the Flask app (`comments_organizer_app`) locally, two main functions (1. clustering, 2. sentiment analysis) must be deployed. \n\n2. In a terminal window (or command prompt in Windows), run the following command to get a token to access the API. Use your Cloud Pak for Data cluster username and password:\n\n```\ncurl -k -X GET https://<cluster-url>/v1/preauth/validateAuth -u <username>:<password>\n```\n\nA json string will be returned. Copy and save the \"accessToken\".\n\n3. Login to IBM Cloud account, click on `Manage` and choose `Access IAM`. Click on `API Keys`. Either create a new key or copy details from the existing key. Choose endpoint listed in [this](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-overview.html) page.\n\n4. Create a Cloud Object Storage instance using the steps list [here](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-provision) if not available and service credentails using the steps \nlisted [here](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-service-credentials). Copy the credentail under `iam_serviceid_crn`  \n\n2. Then once you have your IBM Cloud API Key, Cloud Object Storage crn link, and endpoint details of two deployments, you can go to `comments_organizer_app/app.py`. Search for 'TODO' and:\n     * Replace `wml_credentials` with the credentials you have made in step 3.\n     * Replace `space_tag` with Cloud Object Storage crn link you have made in step 4.\n     * Replace `clustering_endpoint_url` and `sentiment_analysis_endpoint_url` with the correct urls you obtained from step 4 under `Sequence of steps to run`. \n     \n3. Make sure you have all the libraries downdloaded from `requirements.txt`, so run\n```\npip install -r requirements.txt\n```\n4. Now you should be able to run the Flask app. In the directory `comments_organizer_app`, run\n```\npython app.py\n```\nThe app should be visible on http://0.0.0.0:8000/\n\n5. In the web app, you can load example comments by clicking \"Choose File\" then comments_organizer_app -> static -> test_comments_20.txt. Now if click \"Clustering\", \"Sentiment Analysis\", or \"Graphs\" you will get dynamic results based on the comments you upload."}, {"metadata": {"id": "54ae5f72-4293-41d6-a9bf-034929f22fc6"}, "cell_type": "markdown", "source": "**This project contains Sample Materials, provided under license. <br>\nLicensed Materials - Property of IBM. <br>\n\u00a9 Copyright IBM Corp. 2019, 2020. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.<br>**"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}