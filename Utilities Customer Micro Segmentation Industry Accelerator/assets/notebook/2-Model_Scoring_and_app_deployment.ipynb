{"cells": [{"metadata": {"id": "9f09b071-1d3e-4609-891d-7ba4a5054099"}, "cell_type": "markdown", "source": "# Create and Test Scoring Pipeline and Deploy R Shiny Dashboard App"}, {"metadata": {"id": "77ad2eb9-1949-4289-9bf6-12fe1783cfeb"}, "cell_type": "markdown", "source": "### Introduction\n\nNow that we have built the machine learning models, stored and deployed them, we can use the models to cluster new data. \n\nIn the first part of the notebook we will:\n\n* Programmatically get the ID's for the deployment space and model deployments that were created in the 1-model_training notebook.\n* Promote assets required for clustering new data into the deployment space.\n* Create a deployable function which will take raw data for clustering, prep it into the format required for the models and cluster it.\n* Deploy the function.\n* Create the required payload, invoke the deployed function and return clusters.\n\nIn the second part we will:\n* Store Shiny assets into the same deployment space.\n* Deploy Shiny assets as an app and view the dashboard"}, {"metadata": {"id": "a1743776-550f-4386-ac0b-571a89a307af"}, "cell_type": "markdown", "source": "**Sample Materials, provided under license. <br>\nLicensed Materials - Property of IBM. <br>\n\u00a9 Copyright IBM Corp. 2020. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. <br>**"}, {"metadata": {"id": "4a7c9318-153b-4fde-9bc3-ff02b3f588c8"}, "cell_type": "code", "source": "import os\nimport pandas as pd\nimport datetime\nimport json\nfrom ibm_watson_machine_learning import APIClient\nimport os\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"openshift\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"3.5\"\n}\n\nclient = APIClient(wml_credentials)", "execution_count": 1, "outputs": []}, {"metadata": {"id": "ba99a302-f6bc-4d03-8c84-cacd653a4b55"}, "cell_type": "markdown", "source": "### User Inputs\n\nEnter the path to the csv file with raw data to be clustered."}, {"metadata": {"id": "47095e65-20d8-4d1a-b296-596ac575ea19"}, "cell_type": "code", "source": "# specify the location of the csv file with raw data that we would like to score for\ndataset_loc = '/project_data/data_asset/Customer Micro-Segmentation Input.csv'\ndataset_name = os.path.basename(dataset_loc)", "execution_count": 2, "outputs": []}, {"metadata": {"id": "607dcb45-433c-49c1-a157-ecea8a6680ab"}, "cell_type": "markdown", "source": "### Set up Deployment Space, Deployments and Assets\n\nThe following code programmatically gets the deployment space and the pipeline deployment details which were created in **1-model_training**. \n We use the space name and deployment names when creating the deployments as specified below. If multiple deployments within the selected space have the same tag, the most recently created deployment is used.\n\nAlternatively, the user can manually enter the space and deployment guid's.\n\nThe code also promotes a data asset into the deployment space, specifically, the dataset with raw data for scoring. By promoting this asset into the deployment space, it is available and can be accessed by the deployed function."}, {"metadata": {"id": "9034d395-f5d8-41e4-bae7-0671a0d7c5cf"}, "cell_type": "code", "source": "space_name = 'Utilities Customer Micro-Segmentation Space'\n\ndeployment_details_dict = {'lifestlye' : 'lifestyle_pipeline_deployment', 'customer_engagement' : 'customer_engagement_pipeline_deployment'}", "execution_count": 3, "outputs": []}, {"metadata": {"id": "d8d90e6b-f71e-4978-93b7-2e1efcaa58ce"}, "cell_type": "markdown", "source": "Get the space we are working in, which is found using the tag that was hardcoded in **1-model_training**. \n\nIf the user would like to use a different space, manually set the space_id.\n\nSet the space as the default space for working."}, {"metadata": {"id": "684ed0a3-90e9-422d-ab4c-58ac8c9da630"}, "cell_type": "code", "source": "l_space_details = []\nl_space_details_created_times = []\nfor space_details in client.spaces.get_details()['resources']:\n    if space_details['entity']['name'] == space_name:\n        space_id=space_details['metadata']['id']\n\n# set this space as default space\nclient.set.default_space(space_id)", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {"id": "0753b2aa-a09f-4382-b79b-fdbb930071ac"}, "cell_type": "markdown", "source": "Get the deployment id for each pipeline. If there are multiple deployments with the same name in the same space, we take the latest."}, {"metadata": {"id": "86ee020f-7925-48ff-ae25-c264e88df6a3"}, "cell_type": "code", "source": "pipeline_deployments_dict = {}\nfor model, deployment_name in deployment_details_dict.items():\n    # get the id of the deployments - \n    # if there are multiple deployments with the same name in the same space, we take the latest\n    l_deployment_details = []\n    l_deployment_details_created_times = []\n    for deployment in client.deployments.get_details()['resources']:\n        \n\n        if deployment['entity']['name'] == deployment_name:            \n                l_deployment_details.append(deployment)\n                l_deployment_details_created_times.append(datetime.datetime.strptime(deployment['metadata']['created_at'],  '%Y-%m-%dT%H:%M:%S.%fZ'))\n\n    # get the index of the latest created date from the list and use that to get the deployment_id\n    list_latest_index = l_deployment_details_created_times.index(max(l_deployment_details_created_times))\n    deployment_id = l_deployment_details[list_latest_index]['metadata']['id']\n    \n    pipeline_deployments_dict[model] = deployment_id", "execution_count": 5, "outputs": []}, {"metadata": {"id": "af80f485-0a30-47a4-8c7a-b1fe9e3fb749"}, "cell_type": "markdown", "source": "Promote the raw data for scoring asset into the deployment space."}, {"metadata": {"id": "ed3df7ba-8bb2-4956-932a-d2a6b70c3374"}, "cell_type": "code", "source": "dataset_asset_details = client.data_assets.create(dataset_name, file_path=dataset_loc)\ndataset_id = dataset_asset_details['metadata']['guid']", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Creating data asset...\nSUCCESS\n", "name": "stdout"}]}, {"metadata": {"id": "67032df2-5ab9-4a62-8378-964505b20b05"}, "cell_type": "markdown", "source": "## Create the Deployable Function\n\nFunctions can be deployed in Watson Machine Learning in the same way models can be deployed. The python client or REST API can be used to send data to the deployed function. Using the deployed function allows us to prepare the data and pass it to the model for scoring all within the deployed function.\n\nWe start off by creating the dictionary of default parameters to be passed to the function. We get the ID of the asset that has been promoted into the deployment space. We also add the deployment ID and space ID into the dictionary."}, {"metadata": {"id": "1f82b603-6d40-4b58-8942-22c3db81f37e"}, "cell_type": "code", "source": "assets_dict = {'dataset_asset_id' : dataset_id, 'dataset_name' : dataset_name}", "execution_count": 7, "outputs": []}, {"metadata": {"id": "52fa5258-4ab4-4f4f-8668-6e95b6719730"}, "cell_type": "code", "source": "# update wml_credentials. After already creating the client using the credentials, the instance_id gets updated to 999\n# update the instance_id\nwml_credentials[\"instance_id\"] = \"openshift\"\n\nai_parms = {'wml_credentials' : wml_credentials,'space_id' : space_id, 'assets' : assets_dict, 'pipeline_deployment_id' : pipeline_deployments_dict}", "execution_count": 8, "outputs": []}, {"metadata": {"id": "dc0a6800-1770-4f8d-8943-0998cd402d0e"}, "cell_type": "markdown", "source": "### Scoring Pipeline Function\n\nThe function below takes a dictionary of raw data to be scored as a payload. The pipeline completes the remaining steps in prepping the data, passes the data to the model and returns the prediction of lifestyle segments of the customers and their engagements.\n\nThe following rules are required to make a valid deployable function:\n\n* The deployable function must include a nested function named `score`.\n* The score function accepts a list.\n* The list must include an array with the name `values`.\n* The score function must return an array with the name `predictions`, with a list as the value, which in turn contains an array with the name `values`. Example: `{\"predictions\" : [{'values' : }]}`\n* We pass default parameters into the function, credentials and space detail, details of the assets that were promoted into the space and also the model deployment id.\n* The assets are downloaded into the deployment space and imported as variables. The raw data to be scored is then prepared and the function calls the model deployment endpoint to score and return predictions."}, {"metadata": {"id": "59cc9693-7a81-47d1-b8a5-59838e72d604"}, "cell_type": "code", "source": "def scoring_pipeline(parms=ai_parms):\n     \n    import pandas as pd\n    import os\n\n    \n    from ibm_watson_machine_learning import APIClient\n    client = APIClient(parms[\"wml_credentials\"])\n    client.set.default_space(parms['space_id'])\n\n    # use the client to download the stored dataset asset and return the path\n    dataset_path = client.data_assets.download(parms['assets']['dataset_asset_id'], parms['assets']['dataset_name'])\n    df_raw = pd.read_csv(dataset_path)\n    \n    def prep_data(cust_ids, user_inputs):  \n        # filter data to only include customers we are scoring\n        df_prep = df_raw[df_raw[user_inputs['customer_id']].isin(cust_ids)]\n\n        # the order that the customer ids appear in the dataframe may not be in the same order as they were provided in the list in the payload\n        # reorder the dataframe so that the records are in the order of customer ids passed in the payload\n        # we do this by setting the customer id column as the index, then reindexing based on the list provided and resetting the index\n        df_prep.set_index(user_inputs['customer_id'], inplace=True)\n        df_prep = df_prep.reindex(cust_ids).reset_index()\n        \n        # add additional columns that were created as part of the data prep\n        df_prep['NUMBER_OF_QUESTIONS_ANSWERED']=df_prep[user_inputs['survey_cols_to_summarize']].sum(axis=1)\n        df_prep['NUMBER_OF_QUESTIONS_ANSWERED_CAT'] = 'TWO OR THREE'\n        df_prep.loc[df_prep['NUMBER_OF_QUESTIONS_ANSWERED']<=1, 'NUMBER_OF_QUESTIONS_ANSWERED_CAT'] = 'ONE OR LESS'\n        df_prep.loc[df_prep['NUMBER_OF_QUESTIONS_ANSWERED']>=4, 'NUMBER_OF_QUESTIONS_ANSWERED_CAT'] = 'FOUR OR MORE'\n        df_prep['ENERGY_SAVING']=df_prep[user_inputs['energy_usage_cols']].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1)\n                \n        return df_prep\n    \n    def score(payload):\n        \n        cust_ids = payload['input_data'][0]['values']\n        \n        # create variable for the deployment id dictionary\n        pipeline_deployment_id_dict = parms['pipeline_deployment_id']\n        # we stored the user inputs when we deployed each pipeline, as the dictionary is the same in both, just retrieve from first deployment\n        user_inputs_dict = client.deployments.get_details(next(iter(pipeline_deployment_id_dict.values())))['entity']['custom']\n        # call the function to prep the data\n        prepped_data = prep_data(cust_ids, user_inputs_dict)\n\n        # loop through each pipeline and return the cluster assignment\n        results={}\n        for pipeline_name, deployment_id in pipeline_deployment_id_dict.items():\n            if prepped_data is None:\n                return {\"predictions\" : [{'values' : 'Data prep filtered out customer data. Unable to score. Check that the billing date is valid for the input data.'}]}\n            elif prepped_data.shape[0] == 0:\n                return {\"predictions\" : [{'values' : 'Data prep filtered out customer data. Unable to score. Check that the billing date is valid for the input data.'}]}\n            else:\n                print(prepped_data)\n                scoring_payload = {\"input_data\":  [{ \"values\" : prepped_data.values.tolist()}]}\n                predictions = client.deployments.score(deployment_id, scoring_payload)\n                # extract cluster from prediction\n                # in case of customer engagement, where we used kmeans, we increment cluster number by 1 so clusters start at 1 instead of 0\n                l_cluster = []\n                for cluster_num in predictions['predictions'][0]['values']:\n                    cluster = cluster_num[0]\n                    if pipeline_name == 'customer_engagement':\n                        cluster = cluster + 1\n                        \n                    l_cluster.append(cluster)\n                \n                results[pipeline_name] = l_cluster\n                \n        # add customer id list to the dictionary\n        results['cust_ids'] = list(prepped_data[user_inputs_dict['customer_id']])\n        \n        return {\"predictions\" : [{'values' : results}]}\n            \n    return score", "execution_count": 19, "outputs": []}, {"metadata": {"id": "3bd31c7f-7f98-4bf3-97cc-46a34125c9ca"}, "cell_type": "markdown", "source": "### Deploy the Function\n\nThe user can specify the name of the function and deployment in the code below. As we have previously seen, we use tags in the metadata to allow us to programmatically identify the deployed function."}, {"metadata": {"id": "9e9fa69d-96b2-4526-96c4-5daa84782a10"}, "cell_type": "code", "source": "# store the function and deploy it \nfunction_name = 'utilities_customer_micro_segmentation_scoring_pipeline_function'\nfunction_deployment_name = 'utilities_customer_micro_segmentation_scoring_pipeline_function_deployment'", "execution_count": 10, "outputs": []}, {"metadata": {"id": "9ca4cea2-7f1b-4ba2-bd3b-152f4aefae6c"}, "cell_type": "markdown", "source": "\nThe Software Specification refers to the runtime used in the Notebook, WML training and WML deployment. We use the software specification `default_py3.7` to store the function. We get the ID of the software specification and include it in the metadata when storing the function. Available Software specifications can be retrieved using `client.software_specifications.list()`.\n"}, {"metadata": {"id": "8780a2e1-c038-4089-afc5-190649e639b5"}, "cell_type": "code", "source": "\nsoftware_spec_id = client.software_specifications.get_id_by_name(\"default_py3.7\")", "execution_count": 11, "outputs": []}, {"metadata": {"id": "7c6e5f15-885a-456f-b8bf-67540971ce7e"}, "cell_type": "code", "source": "# add the metadata for the function and deployment    \nmeta_data = {\n    client.repository.FunctionMetaNames.NAME : function_name,\n    client.repository.FunctionMetaNames.TAGS : ['utilities_customer_micro_segmentation_scoring_pipeline_function_tag'],\n    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: software_spec_id\n\n}\n\nfunction_details = client.repository.store_function(meta_props=meta_data, function=scoring_pipeline)\n\nfunction_id = function_details[\"metadata\"][\"id\"]\n\nmeta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: function_deployment_name,\n   client.deployments.ConfigurationMetaNames.TAGS : ['utilities_customer_micro_segmentation_scoring_pipeline_function_deployment_tag'],\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\n# deploy the function\nfunction_deployment_details = client.deployments.create(artifact_uid=function_id, meta_props=meta_props)", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '496b26d9-583a-48e9-a09d-621f5dc13ec5' started\n\n#######################################################################################\n\n\ninitializing.......\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='08c8a95e-d356-4333-8b8a-4dc8d35e019d'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {"id": "cd3c0beb-6615-4cbf-a3f1-bcf2dd53144f"}, "cell_type": "markdown", "source": "### Score New Data\n\nGet the guid of the deployed function, create the payload and use the python client to score the data. The deployed function returns Lifestyle and Customer Engagement clusters for the customer.\n\nThe payload contains the ID of the customer who we would like to find the clusters for."}, {"metadata": {"id": "4d8ed598-90c8-4e63-8268-d84fa82a3716"}, "cell_type": "code", "source": "scoring_deployment_id = client.deployments.get_uid(function_deployment_details)\n\npayload = [{\"values\" : [21, 22, 23, 24, 25, 26]}]\n\npayload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload}\n# score\nfunct_output = client.deployments.score(scoring_deployment_id, payload_metadata)\nfunct_output", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "{'predictions': [{'values': {'lifestlye': [3, 2, 2, 2, 2, 1],\n    'customer_engagement': [1, 3, 2, 5, 4, 5],\n    'cust_ids': [21, 22, 23, 24, 25, 26]}}]}"}, "metadata": {}}]}, {"metadata": {"id": "3effa728-8e8c-4ad3-9da1-499c70b015d5"}, "cell_type": "markdown", "source": "# Deploy Shiny App"}, {"metadata": {"id": "77d1aba5-651c-42dd-8742-e69014d0829c"}, "cell_type": "markdown", "source": "In this section we will complete the steps to deploy a Shiny Dashboard in Cloud Pak for Data. The app can be deployed in a similar way to models and functions, using the [ibm-watson-machine-learning](http://ibm-wml-api-pyclient.mybluemix.net/) package.\n\nAll of the files associated with the dashboard are contained in a zip file which is stored in data assets. If the user would like to make changes to the dashboard, they can download the zip from data assets and upload it in the RStudio IDE. "}, {"metadata": {"id": "b9d641cf-1f16-469f-bde9-ba641aa7232a"}, "cell_type": "code", "source": "r_shiny_deployment_name='Utilities_Customer_Micro-Segmentation_Shiny_App'", "execution_count": 14, "outputs": []}, {"metadata": {"id": "f5925ba3-42da-4088-baba-02af7e8c3d32"}, "cell_type": "markdown", "source": "### Store the App\n\nCreate the associated metadata and store the dashboard zip file in the deployment space. "}, {"metadata": {"id": "0f0ba0a9-8fe6-4c53-9a77-5c5c8d087581"}, "cell_type": "code", "source": "# Meta_props to store assets in space \nmeta_props = {\n    client.shiny.ConfigurationMetaNames.NAME: \"Utilities_Customer_Micro-Segmentation_Shiny_assets\",\n    client.shiny.ConfigurationMetaNames.DESCRIPTION: 'Store shiny assets in deployment space' # optional\n}\napp_details = client.shiny.store(meta_props, '/project_data/data_asset/Utilities-Customer-Micro-Segmentation-Analytics-Dashboard.zip')", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Creating Shiny asset...\nSUCCESS\n", "name": "stdout"}]}, {"metadata": {"id": "2e96197b-6407-4f05-b709-6ba779928097"}, "cell_type": "markdown", "source": "### Deploy the App\n\nCreate the metadata for the Shiny deployment by providing  name, description, R-Shiny options and Hardware specifications. R-Shiny configuration provides options on whom you want to share the dashboard with, they are 1) anyone with the link 2) Authenticated users 3) Collaborators in this deployment space"}, {"metadata": {"id": "aadc07e2-c75d-43e1-a4db-54a901996aa2"}, "cell_type": "code", "source": "# Deployment metadata.\ndeployment_meta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: r_shiny_deployment_name,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: 'Deploy Utilities Customer Micro-Segmentation dashboard',\n    client.deployments.ConfigurationMetaNames.R_SHINY: { 'authentication': 'anyone_with_url' },\n    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: { 'name': 'S', 'num_nodes': 1}\n}\n\n# Create the deployment.\napp_uid = client.shiny.get_uid(app_details)\nrshiny_deployment = client.deployments.create(app_uid, deployment_meta_props)", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '0813cd18-e9b0-49aa-b8c7-1d792fdc7b77' started\n\n#######################################################################################\n\n\ninitializing.......\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='3cc5c460-a57c-49b0-8582-beb2d018d218'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {"id": "e603fa93-5087-4e0a-b153-e3ac98aa4ea7"}, "cell_type": "markdown", "source": "### Launch Shiny App\nNow that the dashboard is deployed, it can be accessed through the web browser. The app URL can be found by navigating to the deployed app in the deployment space. \n\nOpen the Navigation Menu, select ***Deployments -> Spaces -> Utilities Customer Micro-Segmentation Space -> Deployments -> Utilities_Customer_Micro-Segmentation_Shiny_App*** to find the dashboard URL.\n\nAlternatively, the path for the app URL can be found from the deployment metadata created in the previous cell. This path should be appended to the user's Cloud Pak for Data hostname to get the complete app URL. To get the path, run the cell below:"}, {"metadata": {"id": "d17b3ddf-bd1c-414d-907e-7e32fd62a40c"}, "cell_type": "code", "source": "print(\"{HOSTNAME}\"+\"/ml/v4/deployments/\"+rshiny_deployment['metadata']['id'] + '/r_shiny')", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "{HOSTNAME}/ml/v4/deployments/3cc5c460-a57c-49b0-8582-beb2d018d218/r_shiny\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}