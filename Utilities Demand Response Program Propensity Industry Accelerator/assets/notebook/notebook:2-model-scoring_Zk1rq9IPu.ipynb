{"cells": [{"metadata": {"id": "73e49406-b5d0-4c6b-b86d-7997c8fab54d"}, "cell_type": "markdown", "source": "## Industry Accelerators - Utilities Demand Response (DR) Program Propensity\n"}, {"metadata": {"id": "9869b957-752e-4e98-9072-4075fe02b58c"}, "cell_type": "markdown", "source": "### Introduction\n\nNow that we have built the machine learning pipeline, stored and deployed it using [ibm-watson-machine-learning](http://ibm-wml-api-pyclient.mybluemix.net), we can use the pipeline to ingest new data, prep it and score it. \n\nBefore executing this notebook on IBM Cloud, you need to:<br>\n1) When you import this project on an IBM Cloud environment, a project access token should be inserted at the top of this notebook as a code cell. <br>\nIf you do not see the cell above, Insert a project token: Click on **More -> Insert project token** in the top-right menu section and run the cell. <br>\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n2) Provide your IBM Cloud API key in the subsequent cell.<br>\n3) You can then step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu.<br>\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Insert IBM Cloud API key\nYour Cloud API key can be generated by going to the <a href=\"https://cloud.ibm.com/iam/apikeys\" target=\"_blank\" rel=\"noopener noreferrer\">API Keys section of the Cloud console</a>. From that page, scroll down to the API Keys section, and click Create an IBM Cloud API key. Give your key a name and click Create, then copy the created key and paste it below. \n\nIf you are running this notebook on cloud pak for data on-prem, leave the ibmcloud_api_key field blank."}, {"metadata": {}, "cell_type": "code", "source": "ibmcloud_api_key = ''", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "try:\n    project\nexcept NameError:\n    # READING AND WRITING PROJECT ASSETS\n    import project_lib\n    project = project_lib.Project() ", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Create and Test Scoring Pipeline \nIn this notebook, we will:\n\n* Programmatically get the ID's for the deployment space and model deployment that were created in the **1-model_training** notebook\n* Create a deployable function which will take raw data for scoring, complete the initial prep, feed it to the pipeline and score it\n* Deploy the function\n* Create the required payload, invoke the deployed function and return predictions\n\n"}, {"metadata": {"id": "49129780-c94f-43a9-b88b-7c4789dd1bfe"}, "cell_type": "code", "source": "import pandas as pd\nimport datetime\nfrom ibm_watson_machine_learning import APIClient\nimport os\n\n\n\nif ibmcloud_api_key != '':\n    wml_credentials = {\n        \"apikey\": ibmcloud_api_key,\n        \"url\": 'https://' + os.environ['RUNTIME_ENV_REGION'] + '.ml.cloud.ibm.com'\n    }\nelse:\n    token = os.environ['USER_ACCESS_TOKEN']\n    wml_credentials = {\n        \"token\": token,\n        \"instance_id\" : \"openshift\",\n        \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n        \"version\": \"3.5\"\n     }\nclient = APIClient(wml_credentials)\n\n", "execution_count": 4, "outputs": []}, {"metadata": {"id": "28d2f92c-cf14-49cb-9e0c-3fab2fc86810"}, "cell_type": "markdown", "source": "### Set up Deployment Space, Deployments and Assets\n\nThe following code programmatically gets the deployment space and the model deployment details which were created in 1-model_training. \nWe use the space name and deployment names that were used when creating the deployments, as specified below. If multiple deployments within the selected space have the same name, the most recently created deployment is used.\nAlternatively, the user can manually enter the space and deployment id's."}, {"metadata": {"id": "60d82aff-a512-4a3c-8986-be4086851182"}, "cell_type": "code", "source": "space_name = 'Utilities Demand Response Propensity Space'\nmodel_name = 'demand_response_propensity_pipeline'\ndeployment_name = 'demand_response_propensity_pipeline_deployment'", "execution_count": 5, "outputs": []}, {"metadata": {"id": "b60ec1d0-68c4-4b78-ab12-eded06fb8236"}, "cell_type": "markdown", "source": "Get the space we are working in, which is found using the name that was hardcoded in **1-model_training**. \nIf you would like to use a different space, manually set the **space_id**.\n\nSet the space as the default space for working."}, {"metadata": {"id": "3d1cac4b-b18d-45fd-9fc6-af5e3626acac"}, "cell_type": "code", "source": "l_space_details = []\nl_space_details_created_times = []\nfor space_details in client.spaces.get_details()['resources']:\n    if space_details['entity']['name'] == space_name:\n        space_id=space_details['metadata']['id']\nprint(\"Setting\",space_name, \"as default space ..\")\n# set this space as default space\nclient.set.default_space(space_id)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Setting Utilities Demand Response Propensity Space as default space ..\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {"id": "c06087ac-7989-481c-ae4b-9336d12d08e4"}, "cell_type": "markdown", "source": "Get the deployment id. If there are multiple deployments with the same name in the same space, we take the latest."}, {"metadata": {"id": "f0323589-6336-4e06-a9e1-bb8323306ebb"}, "cell_type": "code", "source": "l_deployment_details = []\nl_deployment_details_created_times = []\n\nfor deployment in client.deployments.get_details()['resources']:\n        if deployment['entity']['name'] == deployment_name:            \n                l_deployment_details.append(deployment)\n                l_deployment_details_created_times.append(datetime.datetime.strptime(deployment['metadata']['created_at'],  '%Y-%m-%dT%H:%M:%S.%fZ'))\n                \n\n# get the index of the latest created date from the list and use that to get the deployment_id\nlist_latest_index = l_deployment_details_created_times.index(max(l_deployment_details_created_times))\ndeployment_id = l_deployment_details[list_latest_index]['metadata']['id']\nprint(\"Deployment ID of \", deployment_name,\"is\",deployment_id)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Deployment ID of  demand_response_propensity_pipeline_deployment is 45fd4601-9b1f-432b-922c-22e132b028f9\n", "name": "stdout"}]}, {"metadata": {"id": "28a4b475-6971-4b85-afeb-7952b5407de6"}, "cell_type": "markdown", "source": "### Create the Deployable Function\n\nFunctions can be deployed in Watson Machine Learning in the same way models can be deployed. The python client or REST API can be used to send data to the deployed function. Using the deployed function allows us to prepare the data and pass it to the pipeline for scoring all within the deployed function.\n\nWe start off by creating the dictionary of default parameters to be passed to the function. We also add the wml credentials dictionary, model deployment ID and space ID into the dictionary."}, {"metadata": {"id": "fe57ffab-3c6b-4b0c-b4d8-47f7bf080874"}, "cell_type": "code", "source": "# create the wml_credentials again. After already creating the client using the credentials, the instance_id gets updated to 999\n# update the value\nif ibmcloud_api_key == '':\n    wml_credentials[\"instance_id\"] = \"openshift\"  \n\nai_parms = {'wml_credentials' : wml_credentials, 'space_id' : space_id, 'model_deployment_id' : deployment_id}", "execution_count": 11, "outputs": []}, {"metadata": {"id": "7bc6a521-77e9-4429-b1e5-8d26f9fb60c1"}, "cell_type": "markdown", "source": "### Scoring Pipeline Function\n\nThe function below takes a dictionary of raw data to be scored as a payload. Any aggregation on categorical columns that are required is completed before the data is passed to the deployed pipeline. The pipeline completes the remaining steps in prepping the data, passes the data to the model and returns the predicted class and probabilities."}, {"metadata": {"id": "0d0f064a-20ea-40a5-b994-2e3cfe8b275c"}, "cell_type": "code", "source": "def scoring_pipeline(parms=ai_parms):\n    \n    from ibm_watson_machine_learning import APIClient\n    client = APIClient(parms[\"wml_credentials\"])\n    client.set.default_space(parms['space_id'])\n\n    def score(payload):\n        import json\n        import requests\n        import pandas as pd\n     \n        extracted_payload = payload['input_data'][0]['values']\n        \n        # the data passed in from the r shiny app will be in string format\n        # convert to json so we can read it into a dataframe\n        if isinstance(extracted_payload, str):\n            # we need to remove the \\ from the string\n            extracted_payload = extracted_payload.replace('\\\\', '')\n            extracted_payload = json.loads(extracted_payload)\n        \n        # create the dataframe from the values and fields that have been passed in the payload\n        df = pd.DataFrame(extracted_payload)\n        \n        l_customer_ids = df['CUSTOMER_ID'].tolist()\n        \n        # we stored the metadata dictionary when we deployed the pipeline, we retrieve it in the following line of code\n        metadata_dict = client.deployments.get_details(parms['model_deployment_id'])['entity']['custom']  \n        \n        grouping_dict = metadata_dict['grouping_cols']\n        # loop through each key in the dictionary, which is the name of a column that needs some aggregation \n        for key, value_dict in grouping_dict.items():    \n            df[key].replace(value_dict, inplace=True)\n            \n        # all other prep steps are handled by the pipeline - columns not needed are removed, missing values are replaced\n        # use the client to score the data      \n        scoring_payload = [{ \"values\" : df.values.tolist()}]\n        payload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: scoring_payload}\n        predictions = client.deployments.score(parms['model_deployment_id'], payload_metadata)\n        \n        # update the predicted class returned based on our threshold\n        # by default the predicted class is based on 0.5 probability, we changed this based on ROC curve\n        for idx, val in enumerate(predictions['predictions'][0]['values']):\n            if predictions['predictions'][0]['values'][idx][1][1] >= metadata_dict['probability_threshold']:\n                predictions['predictions'][0]['values'][idx][0] = 1\n            else:\n                predictions['predictions'][0]['values'][idx][0] = 0\n\n        return {\"predictions\" : [{'values' : predictions, 'customer_ids' : l_customer_ids}]}\n            \n    return score", "execution_count": 12, "outputs": []}, {"metadata": {"id": "b85b00b2-4387-4c84-a8c3-36676fb5efbf"}, "cell_type": "markdown", "source": "### Deploy the Function\n\nThe user can specify the name of the function and deployment in the code below. As we have previously seen, we use tags in the metadata to allow us to programmatically identify the deployed function."}, {"metadata": {"id": "c0197084-54b9-41aa-8de5-70de52e8f529"}, "cell_type": "code", "source": "# store the function and deploy it \nfunction_name = 'demand_response_propensity_scoring_pipeline_function'\nfunction_deployment_name = 'demand_response_propensity_scoring_pipeline_function_deployment'", "execution_count": 13, "outputs": []}, {"metadata": {"id": "52d77061-8b87-4920-9f57-02386109e36e"}, "cell_type": "markdown", "source": "\nThe Software Specification refers to the runtime used in the Notebook, WML training and WML deployment. We use the `default_py3.7` software specification to store the function. We get the ID of the software specification and include it in the metadata when storing the function. Available Software specifications can be retrieved using `client.software_specifications.list()`."}, {"metadata": {"id": "2fbbfe26-1ef4-4e40-8afa-329a09eb3d29"}, "cell_type": "code", "source": "software_spec_id = client.software_specifications.get_id_by_name(\"default_py3.7\")", "execution_count": 14, "outputs": []}, {"metadata": {"id": "7d4c93c0-9f26-4ced-949d-7ccb2e596c96"}, "cell_type": "code", "source": "\n# add the metadata for the function and deployment    \nmeta_data = {\n    client.repository.FunctionMetaNames.NAME : function_name,\n    client.repository.FunctionMetaNames.TAGS : ['demand_response_propensity_scoring_pipeline_function_tag'],\n    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: software_spec_id\n\n}\n\nfunction_details = client.repository.store_function(meta_props=meta_data, function=scoring_pipeline)\n\nfunction_id = function_details[\"metadata\"][\"id\"]\n\nmeta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: function_deployment_name,\n   client.deployments.ConfigurationMetaNames.TAGS : ['demand_response_propensity_scoring_pipeline_function_deployment_tag'],\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\n# deploy the function\nfunction_deployment_details = client.deployments.create(artifact_uid=function_id, meta_props=meta_props)\n\n", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '3c4d8852-7134-44a5-b7bd-108737f67d8d' started\n\n#######################################################################################\n\n\ninitializing....\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='7e1f3bfb-32dc-4553-ac61-f00b20e1c9f8'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {"id": "bdb5db73-3e57-41c2-a048-9fbc9511bd25"}, "cell_type": "markdown", "source": "### Score New Data\n\nTo create the payload, we pass a dictionary with raw data as the function payload. For demonstration purposes, we will use the same csv file that was used in 1-model_training notebook as the raw data. We take 5 records and convert them into a dictionary form to be passed to the payload.  \n\nWe then get the guid of the deployed function and use the python client to score the data. The deployed function returns the classification prediction along with the probabilities. "}, {"metadata": {"id": "b36c5eae-6a47-4b37-b8a9-80fad409746b"}, "cell_type": "code", "source": "# specify the name of the csv file with raw customer data that we would like to score for\ndataset_name = 'Demand Response View.csv'\n\nmy_file = project.get_file(dataset_name)\nmy_file.seek(0)\ndf_raw_data = pd.read_csv(my_file)\n\n# remove the target variable so the data has the same inputs as training data\ndf_raw_data.drop('DEMAND_RESPONSE', axis=1, inplace=True)", "execution_count": 16, "outputs": []}, {"metadata": {"id": "2bb3c8ce-3686-4808-8950-35613cacc2b3"}, "cell_type": "code", "source": "payload_input_dict = df_raw_data.head(5).to_dict(orient='records')", "execution_count": 17, "outputs": []}, {"metadata": {"id": "3ef8b4d3-5d56-42f6-af0b-4003ce90872d"}, "cell_type": "markdown", "source": "Looking at the payload, not all of these fields are used in the model. Transformers and pipeline will take care of removing columns that aren't used."}, {"metadata": {"id": "cd678514-b77e-4ebe-b3ae-b626241252a3"}, "cell_type": "code", "source": "payload_input_dict[1]", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "{'CUSTOMER_ID': 2,\n 'FIRST_NAME': 'Ima',\n 'LAST_NAME': 'Labadie',\n 'PHONE_1': '505-339-5197',\n 'EMAIL': 'Ima.Labadie@allie.tv',\n 'AGE': 34,\n 'HOME_SIZE': 1770,\n 'ENERGY_USAGE_PER_MONTH': 4970,\n 'ENERGY_EFFICIENCY': 0.35600000000000004,\n 'IS_REGISTERED_FOR_ALERTS': 0,\n 'OWNS_HOME': 1,\n 'COMPLAINTS': 1,\n 'EST_INCOME': 1406,\n 'CLTV': 240.0,\n 'HAS_THERMOSTAT': 1,\n 'HAS_HOME_AUTOMATION': 0,\n 'PV_ZONING': 1,\n 'WIND_ZONING': 0,\n 'SMART_METER_COMMENTS': 'Negative',\n 'IS_CAR_OWNER': 1,\n 'HAS_EV': 0,\n 'HAS_PV': 0,\n 'HAS_WIND': 0,\n 'TENURE': 11,\n 'EBILL': 0,\n 'IN_WARRANTY': 1,\n 'CITY': 'Mountain View',\n 'MARITAL_STATUS': 'U',\n 'GENDER': 'female',\n 'EDUCATION': \"Bachelor's degree\",\n 'EMPLOYMENT': 'Employed full-time',\n 'SEGMENT': 'High Flyers',\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_1': 52098,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_2': 40740,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_3': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_4': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_5': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_6': 26666,\n 'STD_YRLY_USAGE_CUR_YEAR_MINUS_7': 21481,\n 'MEDIAN_YRLY_USAGE_CUR_YEAR_MINUS_1': 20500}"}, "metadata": {}}]}, {"metadata": {"id": "104bfbe4-062b-44b0-bf8f-854b9070193e"}, "cell_type": "code", "source": "scoring_deployment_id = client.deployments.get_uid(function_deployment_details)\n\npayload = [{'values' : payload_input_dict}]\n\npayload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload}\n# score\nfunct_output = client.deployments.score(scoring_deployment_id, payload_metadata)\nfunct_output", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "{'predictions': [{'values': {'predictions': [{'fields': ['prediction',\n       'probability'],\n      'values': [[0, [0.9356245398521423, 0.06437547504901886]],\n       [0, [0.8601992130279541, 0.1398007571697235]],\n       [1, [0.14609456062316895, 0.853905439376831]],\n       [0, [0.9098342657089233, 0.09016572684049606]],\n       [0, [0.886391818523407, 0.11360820382833481]]]}]},\n   'customer_ids': [1, 2, 3, 4, 5]}]}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "**The R Shiny Dashboard invokes this scoring pipeline for visualizing the results.**<br>\n**Follow the instructions in Readme to launch the R-Shiny dashboard.**\n<hr>\n\nSample Materials, provided under <a href=\"https://github.com/IBM/Industry-Accelerators/blob/master/CPD%20SaaS/LICENSE\" target=\"_blank\" rel=\"noopener noreferrer\">license.</a> <br>\nLicensed Materials - Property of IBM. <br>\n\u00a9 Copyright IBM Corp. 2020, 2021. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. <br>"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}